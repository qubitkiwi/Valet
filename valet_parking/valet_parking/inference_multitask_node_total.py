# -*- coding: utf-8 -*-

import cv2
import numpy as np
import torch
import torch.nn.functional as F

import rclpy
from rclpy.node import Node
from geometry_msgs.msg import Twist
from sensor_msgs.msg import CompressedImage
from typing import Dict, Tuple, Optional

# â˜… ì €ì¥í•´ë‘” ëª¨ë¸ íŒŒì¼ëª…ê³¼ Class ì´ë¦„ì´ ë§ëŠ”ì§€ ê¼­ í™•ì¸í•˜ì„¸ìš”!
from .mobilenetv3s_parking_model_pretrained_multi import MultiCamParkingModel



# -------------------------
# ì„¤ì • (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ë§ì¶°ì•¼ í•¨)
# -------------------------
IMG_WIDTH = 224
IMG_HEIGHT = 224
NUM_CLASSES = 2  # â˜… í•™ìŠµí•  ë•Œ ì„¤ì •í•œ í´ë˜ìŠ¤ ê°œìˆ˜

# â˜… í•™ìŠµ ì½”ë“œì˜ CROP_SETTINGSì™€ 100% ë™ì¼í•´ì•¼ í•¨
CROP_SETTINGS = {
    'front_cam': (0, 480, 0, 640),
    'rear_cam':  (0, 480, 0, 640),
    'left_cam':  (0, 300, 100, 640),
    'right_cam': (0, 300, 0, 540)
}

# í‘œì§€íŒ/ìƒíƒœ ì´ë¦„ (ë¡œê·¸ ì¶œë ¥ìš©)
CLASS_NAMES = {
    0: "ì£¼ì°¨ ì¤‘",
    1: "ì£¼ì°¨ ì™„ë£Œ"
}

# -----------------------------------------------------------
# ParkingSafetyController í´ë˜ìŠ¤ ì •ì˜
# -----------------------------------------------------------
class ParkingSafetyController:
    def __init__(self, stop_threshold: float = 0.9):
        """
        Args:
            stop_threshold (float): ì •ì§€ë¥¼ íŠ¸ë¦¬ê±°í•  í™•ë¥  ì„ê³„ê°’ (ê¸°ë³¸ 0.9 = 90%) 
        """
        self.stop_threshold = stop_threshold

        self.is_parking_finished = False

    def apply_safety_logic(self, linear_x: float, angular_z: float, prob_complete: float):
        """
        ì£¼ì°¨ ì™„ë£Œ í™•ë¥ (prob_complete)ì´ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ì†ë„ë¥¼ 0ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
        
        Returns:
            linear_x, angular_z, is_stopped (bool)
        """
        # 1. ìƒíƒœ ì—…ë°ì´íŠ¸: ì•„ì§ ì•ˆ ëë‚¬ëŠ”ë°, ì´ë²ˆì— í™•ë¥ ì´ ê¸°ì¤€ì„ ë„˜ì—ˆë‹¤ë©´ 'ì™„ë£Œ' ìƒíƒœë¡œ ë³€ê²½
        if not self.is_parking_finished:
            if prob_complete >= self.stop_threshold:
                self.is_parking_finished = True

        # 2. ì œì–´ ì ìš©: ì™„ë£Œ ìƒíƒœë¼ë©´ ë¬´ì¡°ê±´ 0 ì¶œë ¥
        if self.is_parking_finished:
            return 0.0, 0.0, True  # (ì†ë„, ì¡°í–¥, ì •ì§€ìƒíƒœì—¬ë¶€)
            
        # ì™„ë£Œ ìƒíƒœê°€ ì•„ë‹ˆë¼ë©´ ì›ë˜ ê°’ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return linear_x, angular_z, False

# -----------------------------------------------------------
# Utils
# -----------------------------------------------------------
def stamp_to_sec(stamp) -> float:
    return float(stamp.sec) + float(stamp.nanosec) * 1e-9

def decode_jpeg_to_bgr(data: bytes) -> Optional[np.ndarray]:
    arr = np.frombuffer(data, dtype=np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)  # BGR
    return img

def preprocess_like_train(img_bgr: np.ndarray, cam_name: str) -> np.ndarray:
    """
    í•™ìŠµ ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ìˆ˜í–‰
    1. BGR -> RGB
    2. Crop
    3. Resize
    4. Transpose (C, H, W)
    """
    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

    # 2. Crop ì ìš©
    if cam_name in CROP_SETTINGS:
        y1, y2, x1, x2 = CROP_SETTINGS[cam_name]
        h, w, _ = img.shape
        y1 = max(0, y1); x1 = max(0, x1)
        y2 = min(h, y2); x2 = min(w, x2)
        
        if y2 > y1 and x2 > x1:
            img = img[y1:y2, x1:x2]

    # 3. Resize
    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))
    
    # 4. (H, W, C) -> (C, H, W)
    img = np.transpose(img, (2, 0, 1))
    
    # Float32 ë³€í™˜ (Normalizationì€ ëª¨ë¸ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰ë¨)
    return img.astype(np.float32)


# -----------------------------------------------------------
# .Main Node Class
# -----------------------------------------------------------
class MultiTaskInferNode(Node):
    def __init__(self):
        super().__init__('multitask_infer_node')

        # íŒŒë¼ë¯¸í„° ì„ ì–¸
        self.declare_parameter('cams', ['front_cam', 'rear_cam', 'left_cam', 'right_cam'])
        self.declare_parameter('ckpt_path', '/home/hyunii/everything/parking/multi/mobilenetv3s_pretrained_up_mid_crop_LR_cls_04_sampler_onecycle_batch256_epoch100_lr0001/best_model.pth') # ê²½ë¡œ ìˆ˜ì • í•„ìš”
        self.declare_parameter('linear_gain', 1.0) # ì†ë„ ë°°ìœ¨
        self.declare_parameter('angular_gain', 1.0) # ì¡°í–¥ ë°°ìœ¨
        

        self.cams = list(self.get_parameter('cams').value)
        self.ckpt_path = self.get_parameter('ckpt_path').value
        self.linear_gain = self.get_parameter('linear_gain').value
        self.angular_gain = self.get_parameter('angular_gain').value

        # â˜… [ìˆ˜ì •] ì•ˆì „ ì œì–´ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™” ===================================================================================
        self.declare_parameter('stop_prob_threshold', 0.9)
        stop_threshold = self.get_parameter('stop_prob_threshold').value

        self.safety_controller = ParkingSafetyController(stop_threshold=stop_threshold)
        self.get_logger().info(f"ğŸ›¡ï¸ Safety Controller Active (Stop Threshold: {stop_threshold*100:.1f}%)")
        # ==================================================================================================================

        # ë™ê¸°í™” ì„¤ì •
        self.sync_slop = 0.1
        self.pub_hz = 10.0

        # Device ì„¤ì •
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.get_logger().info(f"ğŸš€ Using Device: {self.device}")

        # ---------------------------
        # ëª¨ë¸ ë¡œë“œ (Multi-Task)
        # ---------------------------
        self.get_logger().info("â³ Loading Model...")
        # â˜… í•™ìŠµ ì‹œ ì‚¬ìš©í•œ num_classesì™€ ë™ì¼í•´ì•¼ í•¨
        self.model = MultiCamParkingModel(pretrained=True, num_classes=NUM_CLASSES).to(self.device)
        
        if self.ckpt_path:
            checkpoint = torch.load(self.ckpt_path, map_location=self.device)
            self.model.load_state_dict(checkpoint)
            self.get_logger().info(f"âœ… Loaded weights from {self.ckpt_path}")
        else:
            self.get_logger().warn("âš ï¸ No checkpoint path provided!")

        self.model.eval()

        # ì´ë¯¸ì§€ ë²„í¼ ì´ˆê¸°í™”
        self.img_buf: Dict[str, Tuple[float, bytes]] = {}

        # Publisher / Subscriber
        self.pub_cmd = self.create_publisher(Twist, '/controller/cmd_vel', 10)

        for cam in self.cams:
            topic = f'/{cam}/image/compressed' # í† í”½ëª… í™•ì¸ í•„ìš” (ex: /front_cam/image/compressed)
            self.create_subscription(
                CompressedImage,
                topic,
                lambda msg, c=cam: self.on_img(c, msg),
                1
            )

        # íƒ€ì´ë¨¸ ì‹¤í–‰
        period = 1.0 / self.pub_hz
        self.create_timer(period, self.tick)
        self.get_logger().info("âœ¨ Node Ready.")

    def on_img(self, cam: str, msg: CompressedImage):
        if cam not in self.cams: return
        t = stamp_to_sec(msg.header.stamp)
        self.img_buf[cam] = (t, bytes(msg.data))
        
        # ë²„í¼ ê´€ë¦¬ (ë„ˆë¬´ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ)
        if len(self.img_buf) > 16:
            oldest = min(self.img_buf.keys(), key=lambda k: self.img_buf[k][0])
            del self.img_buf[oldest]

    def _pop_synced(self) -> Optional[Dict[str, bytes]]:
        # 4ê°œ ì¹´ë©”ë¼ ë°ì´í„°ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
        for cam in self.cams:
            if cam not in self.img_buf: return None
            
        times = [self.img_buf[cam][0] for cam in self.cams]
        if (max(times) - min(times)) > self.sync_slop:
            # ì‹±í¬ ì•ˆ ë§ìœ¼ë©´ ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ë²„ë¦¼
            oldest = min(self.cams, key=lambda c: self.img_buf[c][0])
            del self.img_buf[oldest]
            return None
            
        out = {cam: self.img_buf[cam][1] for cam in self.cams}
        self.img_buf.clear()
        return out

    @torch.no_grad()
    def tick(self):
        synced = self._pop_synced()
        if synced is None: return

        # 1. ì „ì²˜ë¦¬ (4ê°œ ì´ë¯¸ì§€ -> Tensor)
        images_list = []
        for cam in self.cams:
            bgr = decode_jpeg_to_bgr(synced[cam])
            if bgr is None: return
            img_tensor = preprocess_like_train(bgr, cam) # (C,H,W)
            images_list.append(img_tensor)
        
        # Stack -> (1, 4, 3, 224, 224)
        x_np = np.stack(images_list, axis=0)
        x_tensor = torch.from_numpy(x_np).unsqueeze(0).to(self.device)

        # 2. ëª¨ë¸ ì¶”ë¡ 
        outputs = self.model(x_tensor)
        
        # 3. ê²°ê³¼ íŒŒì‹±
        # (1) ì œì–´ê°’ (Regression)
        control_out = outputs['control'] # (B, 2)
        linear_x = control_out[0, 0].item() * self.linear_gain
        angular_z = control_out[0, 1].item() * self.angular_gain
        
        # (2) ë¶„ë¥˜ê°’ (Classification)
        class_out = outputs['class']     # (B, num_classes)
        probs = F.softmax(class_out, dim=1)
        p0 = probs[0, 0].item()
        p1 = probs[0,1].item()
        pred_idx = torch.argmax(probs, dim=1).item()
        confidence = probs[0, pred_idx].item() * 100.0
        
        pred_str = CLASS_NAMES.get(pred_idx, f"Unknown({pred_idx})")

        # -----------------------------------------------------------
        # â˜… [ìˆ˜ì •] ëª¨ë“ˆí™”ëœ ì•ˆì „ ë¡œì§ ì ìš©
        #   (í•œ ë²ˆ ë©ˆì¶”ë©´ ê³„ì† 0 ë°˜í™˜)
        # -----------------------------------------------------------
        linear_x, angular_z, is_stopped = self.safety_controller.apply_safety_logic(
            linear_x, angular_z, p1
        )

        if is_stopped:
        #     # ë¡œê·¸ë„ í™•ì‹¤í•˜ê²Œ ë³€ê²½
            pred_str = "ğŸ›‘ PARKING COMPLETE (Holding STOP)"
        # -----------------------------------------------------------


        # 4. ì œì–´ ë©”ì‹œì§€ ë°œí–‰
        msg = Twist()
        msg.linear.x = float(linear_x)
        msg.angular.z = float(angular_z)
        self.pub_cmd.publish(msg)

        # 5. ë¡œê¹…
        self.get_logger().info(
            f"ğŸš— V: {linear_x:.3f}, W: {angular_z:.3f} | "
            f"ğŸ›‘ State: {pred_str} ({confidence:.1f}%) | "
            f"p0={p0:.3f}, p1={p1:.3f}"
        )

def main(args=None):
    rclpy.init(args=args)
    node = MultiTaskInferNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()